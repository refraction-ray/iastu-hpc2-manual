This section reviews some general workflow for daily administration on the cluster.

## some scenarios

### add a new user

* Add user account and password info into ansible user playbook and run it.
* The password can be generated by `openssl rand -base64 32`, see [here](https://www.howtogeek.com/howto/30184/10-ways-to-generate-a-random-password-from-the-command-line/) for more approaches to generate random password.
* `sacctmgr add user <name> account=n3` to make user available to slurm. (already merged into ansible workflow)
* `sudo setquota -u <name> 60G 80G 0 0 /` (already merged into ansible workflow)
* mkdir on /DATA path. (already merged into ansible workflow)
* Probably add `<user> cpu usersoft/` line in `/etc/cgrules.conf`. And `sudo cgrulesengd`. (edit in roles/cgroup/files and run ansible cgroup role instead) **Unincluded**
* Activate mathematica by ansible one-liner. **Unincluded**
* ~~Add backup crontab for user home directory. **Unincluded**~~ taken over by restic as a whole

### add new compute nodes

There is bootstrap script hosted on master in /home/ubuntu/bootstrap. You can open a simple http server in this dir on matser. On newly introduced nodes, just run `bash <(curl -s http://192.168.48.10:8000/bt.sh)`. And it is enough to run ansible workflows from master now.

### after reboot

* It is highly suggested that all ansible playbooks to be executed once reboot (at least network and basic for compute node reboot).
* config cgroup as `sudo cgconfigparser -l /etc/cgconfig.conf && sudo cgrulesengd`.
* start tinc vpn by `sudo tincd -n debug`.
* iptables (nat rules) on master is not persistent, see [this issue](https://github.com/ansible/ansible/issues/25149) for further develpment of ansible to incorporate persistence of iptables.
* ~~hostname is not persistent by hostname module of ansible!! [see issue](https://github.com/ansible/ansible/issues/54755)~~ Solved by switch option in cloud.cfg.
* MTU is not persistent by netplan, due to default cloud init in ubuntu (no good even after add mac match to netplan...)
* may need to set `scontrol update nodename=cx state=IDLE` by hand to make them online again in slurm

### summary on works beyond ansible workflow

All extras in master nodes, keep the bottom line that all tasks on compute node should be merged into ansible workflow.

* local nonsytem disk partition and make filesystem
* hard disk mount and fstab configure (one time forever, required before **basic roles**, actually can easily merged into basic role)~~ already merged into ansible workflow
* ~~Possible nvidia drivers install and reboot if GPU is available.~~(already merged into ansible workflow) Cuda and cudnn can be managed by spack.
* quota initial configure (one time forever, required before **user roles)**
* intel parallel studio install (one time forever) (no need to install before any roles, possible issue for python path maybe in **python roles**)
* mathematica install and add virtual mathematica packages in spack (one time forever) (no need to install before any roles). Similar for Matlab (but it has a predefined recipe).
* ~~backup crontabs (one time forever? maybe find some more advanced tools) (no need to configure before any roles)~~ changed to use restic for backup
* python packages install and jupyter configure (continuing work) (no need to install before any roles)
* spack packages install by specs and spack env maintenance (continuing work) (no need to install before any roles)
* sacctmgr ~~cluster~~, qos, priority and account add (continuing work for advanced scenario, minimum setup required before **user roles** after slurm roles)
* ~~two line of commands to final set up ELK stack on master (should find some more elegant way in the future)~~  merged into ansible workflow
* tinc vpn set up on master node
* docker set up on master node
* ~~restic backup setup on master node~~, merged into ansible workflow

### install softwares or libraries beyond spack

Installation path: large size commercial softwares: `/opt/softwarename/version/`. Open source library from source: `/home/ubuntu/softwares/softwarename`, in this dir, you may have some name+ver dir for installed versions of softwares and some dir name ended with src as source files. Hopefully, one should put a self-contained information file in each software dir. The name convention is `softwarename.info`. The content includes what each dir within for, what the notes and warnings for this software configuration and installation, most importantly, the install process details for each installed version, such as options for `./configure` and so on. One may even want to capture all stdout for configure and make on each installed version dir with name `configure.out`, `make.out` and so on. To record this stdout more easily, using `script cmake.out` and then run `cmake`, remember ctrl-d or exit to stop the recording. See [more](https://www.geeksforgeeks.org/script-command-in-linux-with-examples/) on script command in linux.

Finally, you may want to include such libraries under the control of spack. This usually involves two steps. If such library already has a position in spack repo, then you only need to add the external path for this package in spack config packages.yaml. If there is some more further fine tuning on module files to load it, you need further hacking spack config modules.yaml. (All these config change should go under ansible workflow). Besides, if the softwares is not registered in spack, then you need first add a package.py in repo as a placeholder. Something as below is enough.

```python
# placeholder for external mma

from spack import *

class Mathematica(Package):

    homepage = "https://www.wolfram.com/mathematica/"

    version('11.0')
```

The insipration of standard workflow on software installation is from [this post](http://www.admin-magazine.com/HPC/Articles/Warewulf-Cluster-Manager-Development-and-Run-Time/(language)/eng-US).

## Known Issues

* MTU cannot be set by netplan yml file, even after we have included the mac:address line in the yml.

  Current Workaround: Include directly command on ip in ansible playbooks.

* Burst of NFS error logs, in master we have: 

  ```bash
  nfsd4_validate_stateid: 270 callbacks suppressed
  NFSD: client 192.168.*.* testing state ID with incorrect client ID
  ```

  And in client, we have: `NFS: nfs4_reclaim_open_state: Lock reclaim failed ` but with lower frequency. Meanwhile, the IO speed for NFS drop to 1/10 of normal speed.

  Current Workaround: cannot find any better solution currently, but rebooting of clients seem to be fine and make all these errors vanish. Possibly related to some Linux kernel NFS bugs.

* Burst of errors: `watchdog: BUG: soft lockup - CPU#20 stuck for 23s! [192.168.*.10-m:27452]` in one of the compute nodes and final crash of the machine though ping is still available then. 

  Current Workaround: Maybe related to the above bug but not sure. Just a hard reboot solves everything.

* Error log of ganglia client claiming that some python module won't work `/usr/sbin/gmond[2358]: [PYTHON] Can't call the metric handler function for [tcpext_tcploss_percentage] in the python module [netstats]`. But this is not true, a reboot can make these error vanishing and every loaded module is workable for gmond.

  Current Workaround: Restarting ganglia-monitor service should be enough.

* Sometimes, after restart of gmond, it cannot collect all metric, some are missed.

  Current Workaround: No idea why. Just try restarting gmond service, but it may still not work. In sum, gmond status is somewhat fragile and tend to miss some metric. Maybe related to this [so](https://serverfault.daytorrents.com/a/422273/25640), try configuring `send_metadata_interval` to nonzero if one use unicast for gmond.